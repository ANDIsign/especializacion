{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ANDIsign/especializacion/blob/main/Modelo_final_OK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2H_QsTNHavn"
      },
      "outputs": [],
      "source": [
        "# Instalación de dependencias\n",
        "!pip install google-play-scraper transformers torch\n",
        "\n",
        "# Importación de librerías\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from google_play_scraper import Sort, reviews\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.utils import resample\n",
        "\n",
        "\n",
        "# Configuración inicial\n",
        "CONFIG = {\n",
        "    'app_id': 'com.netflix.mediaclient',\n",
        "    'lang': 'es',\n",
        "    'country': 'co',\n",
        "    'sort': Sort.NEWEST,\n",
        "    'max_len': 30,\n",
        "    'batch_size': 32,\n",
        "    'epochs': 10,\n",
        "    'n_classes': 2,\n",
        "    'random_seed': 42,\n",
        "    'pre_trained_model_name': 'bert-base-cased'\n",
        "}\n",
        "\n",
        "# Configuración de semilla para reproducibilidad\n",
        "np.random.seed(CONFIG['random_seed'])\n",
        "torch.manual_seed(CONFIG['random_seed'])\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Dispositivo usado: {device}\")\n",
        "\n",
        "# Función para limpiar el texto\n",
        "def limpiar_texto(texto):\n",
        "    if isinstance(texto, str):\n",
        "        texto = texto.lower()\n",
        "        texto = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', texto)\n",
        "        texto = re.sub(r'\\@\\w+|\\#', '', texto)\n",
        "        texto = re.sub(r\"[^a-zA-Z0-9áéíóúñÁÉÍÓÚÑ\\s]\", '', texto)\n",
        "    return texto\n",
        "\n",
        "# Función para preparar el dataset y etiquetar las reseñas\n",
        "def prepare_dataset(df, label_threshold=3):\n",
        "    df['label'] = df['score'].apply(lambda x: 0 if x <= label_threshold else 1)\n",
        "    return df[['content', 'label']].dropna().reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Función para extraer reseñas\n",
        "def obtener_reseñas(app_id, lang, country, sort):\n",
        "    all_reviews = []\n",
        "    next_token = None\n",
        "    while True:\n",
        "        reviews_batch, next_token = reviews(\n",
        "            app_id,\n",
        "            lang=lang,\n",
        "            country=country,\n",
        "            sort=sort,\n",
        "            continuation_token=next_token\n",
        "        )\n",
        "        # Filtrar las reseñas del año 2024\n",
        "        reviews_filtered = [r for r in reviews_batch if r['at'].year == 2024]\n",
        "        if not reviews_filtered:\n",
        "            break\n",
        "        all_reviews.extend(reviews_filtered)\n",
        "\n",
        "        if not next_token or not reviews_filtered:\n",
        "            break\n",
        "    return pd.DataFrame(all_reviews)\n",
        "\n",
        "# Obtener reseñas de la aplicación\n",
        "df = obtener_reseñas(CONFIG['app_id'], CONFIG['lang'], CONFIG['country'], CONFIG['sort'])\n",
        "\n",
        "# Verificar si se obtuvieron datos\n",
        "if df.empty:\n",
        "    raise ValueError(\"No se obtuvieron datos de la API. Verifica la configuración.\")\n",
        "\n",
        "# Limpiar el DataFrame\n",
        "df['content'] = df['content'].apply(limpiar_texto)\n",
        "\n",
        "# Preparar el dataset\n",
        "df_modelo = prepare_dataset(df)\n",
        "\n",
        "print(f\"Número de reseñas extraídas: {len(df_modelo)}\")\n",
        "\n",
        "# Tomar una muestra aleatoria de n ejemplos\n",
        "df_modelo_sample = df_modelo.sample(n=1000, random_state=CONFIG['random_seed']).reset_index(drop=True)\n",
        "\n",
        "# Balancear el dataset\n",
        "def balancear_datos(df):\n",
        "    clase_mayoritaria = df[df.label == df.label.value_counts().idxmax()]\n",
        "    clase_minoritaria = df[df.label != df.label.value_counts().idxmax()]\n",
        "    clase_minoritaria_oversampled = resample(\n",
        "        clase_minoritaria,\n",
        "        replace=True,\n",
        "        n_samples=len(clase_mayoritaria),\n",
        "        random_state=CONFIG['random_seed']\n",
        "    )\n",
        "    df_balanceado = pd.concat([clase_mayoritaria, clase_minoritaria_oversampled]).sample(frac=1, random_state=CONFIG['random_seed'])\n",
        "    return df_balanceado\n",
        "\n",
        "# Balancear la muestra\n",
        "df_modelo_sample_balanceado = balancear_datos(df_modelo_sample)\n",
        "\n",
        "# Dividir el dataset balanceado en entrenamiento y prueba\n",
        "df_train, df_test = train_test_split(df_modelo_sample_balanceado, test_size=0.2, random_state=CONFIG['random_seed'])\n",
        "\n",
        "# Dataset personalizado para BERT\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, contents, labels, tokenizer, max_len):\n",
        "        self.contents = contents\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.contents)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        content = str(self.contents[idx])\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            content,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Función para crear el DataLoader\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "    dataset = SentimentDataset(\n",
        "        contents=df.content.to_numpy(),\n",
        "        labels=df.label.to_numpy(),\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len\n",
        "    )\n",
        "    return DataLoader(dataset, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "# Crear DataLoaders\n",
        "tokenizer = BertTokenizer.from_pretrained(CONFIG['pre_trained_model_name'])\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, CONFIG['max_len'], CONFIG['batch_size'])\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, CONFIG['max_len'], CONFIG['batch_size'])\n",
        "\n",
        "# Modelo BERT\n",
        "class BERTSentimentClassifier(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(BERTSentimentClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(CONFIG['pre_trained_model_name'])\n",
        "        self.drop = nn.Dropout(p=0.2)\n",
        "        self.linear = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        cls_output = self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
        "        return self.linear(self.drop(cls_output))\n",
        "\n",
        "# Configuración del modelo\n",
        "model = BERTSentimentClassifier(CONFIG['n_classes']).to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5, weight_decay=0.01) # lr=1e-6 anterior\n",
        "total_steps = len(train_data_loader) * CONFIG['epochs']\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps)\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# Early Stopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0, verbose=False, path='best_model.pt'):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.verbose = verbose\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None or val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.save_checkpoint(model)\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping contador: {self.counter} de {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "    def save_checkpoint(self, model):\n",
        "        if self.verbose:\n",
        "            print('Guardando el mejor modelo ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "\n",
        "# Funciones de entrenamiento y evaluación\n",
        "def train_epoch(model, data_loader, loss_fn, optimizer, scheduler, device, n_examples):\n",
        "    model.train()\n",
        "    correct_predictions, losses = 0, []\n",
        "    for batch in data_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        losses.append(loss.item())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "    model.eval()\n",
        "    correct_predictions, losses = 0, []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            losses.append(loss.item())\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "# Entrenamiento y evaluación\n",
        "def train_model(model, train_data_loader, test_data_loader, optimizer, scheduler, loss_fn, n_train_examples, n_test_examples):\n",
        "    best_accuracy = 0\n",
        "    early_stopping = EarlyStopping(patience=3, verbose=True)\n",
        "    for epoch in range(CONFIG['epochs']):\n",
        "        print(f\"Epoch {epoch + 1}/{CONFIG['epochs']}\")\n",
        "\n",
        "        # Entrenamiento\n",
        "        train_acc, train_loss = train_epoch(model, train_data_loader, loss_fn, optimizer, scheduler, device, n_train_examples)\n",
        "        print(f\"Entrenamiento - Precisión: {train_acc} - Pérdida: {train_loss}\")\n",
        "\n",
        "        # Evaluación\n",
        "        val_acc, val_loss = eval_model(model, test_data_loader, loss_fn, device, n_test_examples)\n",
        "        print(f\"Evaluación - Precisión: {val_acc} - Pérdida: {val_loss}\")\n",
        "\n",
        "        # Early Stopping\n",
        "        early_stopping(val_loss, model)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Entrenamiento detenido temprano\")\n",
        "            break\n",
        "\n",
        "        # Guardar el mejor modelo\n",
        "        if val_acc > best_accuracy:\n",
        "            best_accuracy = val_acc\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "\n",
        "# Entrenar el modelo\n",
        "train_model(model, train_data_loader, test_data_loader, optimizer, scheduler, loss_fn, len(df_train), len(df_test))\n",
        "\n",
        "# Cargar el mejor modelo\n",
        "model.load_state_dict(torch.load('best_model.pt'))\n",
        "\n",
        "# Evaluación final\n",
        "y_pred = []\n",
        "y_true = df_test['label'].tolist()\n",
        "for batch in test_data_loader:\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "# Reporte de métricas\n",
        "print(\"Reporte de clasificación:\\n\", classification_report(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Visualizar la matriz de confusión con un mapa de calor\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Clase 0', 'Clase 1'], yticklabels=['Clase 0', 'Clase 1'])\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Verdadero')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n",
        "\n",
        "# Cálculos de métricas\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "# Imprimir las métricas\n",
        "print(f\"Precisión: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "IfMqn-s3zQNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Calcular probabilidades de clase positiva\n",
        "y_probs = []  # Probabilidades de predicción de la clase positiva\n",
        "model.eval()\n",
        "for batch in test_data_loader:\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        probs = torch.nn.functional.softmax(outputs, dim=1)[:, 1]\n",
        "        y_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "# Calcular curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Graficar la curva ROC\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Línea aleatoria\n",
        "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
        "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JLK59Lqb5ANN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "# Calcular precisión y recall en diferentes umbrales\n",
        "precision, recall, thresholds = precision_recall_curve(y_true, y_probs)\n",
        "average_precision = average_precision_score(y_true, y_probs)\n",
        "\n",
        "# Graficar la curva de Precisión-Recall\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='green', lw=2, label=f'AP = {average_precision:.2f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precisión')\n",
        "plt.title('Curva Precisión-Recall')\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HtAAuY8z6jDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribución de probabilidades predichas\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(y_probs, bins=20, color='blue', alpha=0.7, label='Probabilidad Clase 1')\n",
        "plt.axvline(x=0.5, color='red', linestyle='--', label='Umbral 0.5')\n",
        "plt.xlabel('Probabilidad Predicha')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('Distribución de Probabilidades de Predicción')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "McXeDOev6lOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer Falsos Positivos y Falsos Negativos\n",
        "df_test['y_pred'] = y_pred\n",
        "falsos_positivos = df_test[(df_test['label'] == 0) & (df_test['y_pred'] == 1)]\n",
        "falsos_negativos = df_test[(df_test['label'] == 1) & (df_test['y_pred'] == 0)]\n",
        "\n",
        "print(f\"Número de Falsos Positivos: {len(falsos_positivos)}\")\n",
        "print(f\"Número de Falsos Negativos: {len(falsos_negativos)}\")\n",
        "\n",
        "# Opcional: Visualizar ejemplos específicos\n",
        "print(\"Ejemplos de Falsos Positivos:\")\n",
        "print(falsos_positivos['content'].head())\n",
        "\n",
        "print(\"Ejemplos de Falsos Negativos:\")\n",
        "print(falsos_negativos['content'].head())\n"
      ],
      "metadata": {
        "id": "64MwuHa76nFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encontrar el umbral óptimo\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
        "best_threshold = thresholds[np.argmax(f1_scores)]\n",
        "print(f\"Umbral óptimo: {best_threshold}\")\n"
      ],
      "metadata": {
        "id": "0-poQBtE7qUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Recalcular predicciones con el umbral óptimo\n",
        "optimal_threshold = 0.058853041380643845\n",
        "y_pred_optimal = [1 if prob > optimal_threshold else 0 for prob in y_probs]\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "print(\"Reporte de clasificación con umbral óptimo:\")\n",
        "print(classification_report(y_true, y_pred_optimal))\n"
      ],
      "metadata": {
        "id": "iMilGfwC8lIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar la Curva ROC\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# Ajustar el índice para el umbral óptimo\n",
        "threshold_idx = np.argmin(np.abs(thresholds - optimal_threshold))\n",
        "if threshold_idx >= len(fpr):  # Garantizar que el índice esté dentro del rango\n",
        "    threshold_idx = len(fpr) - 1\n",
        "\n",
        "# Agregar el punto del umbral óptimo a la curva\n",
        "plt.scatter(fpr[threshold_idx],\n",
        "            tpr[threshold_idx],\n",
        "            color='red', label=f'Umbral Óptimo ({optimal_threshold:.2f})')\n",
        "\n",
        "# Línea diagonal aleatoria\n",
        "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
        "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
        "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
        "plt.title('Curva ROC con Umbral Óptimo')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1K4lodlB8nOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Recalcular predicciones con el umbral óptimo\n",
        "y_pred_optimal = [1 if prob > optimal_threshold else 0 for prob in y_probs]\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "print(\"Reporte de clasificación con el umbral óptimo:\")\n",
        "print(classification_report(y_true, y_pred_optimal))\n"
      ],
      "metadata": {
        "id": "SIuOfXUf9B4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calcular predicciones con umbral por defecto (0.5)\n",
        "y_pred_default = [1 if prob > 0.5 else 0 for prob in y_probs]\n",
        "\n",
        "# Calcular predicciones con umbral óptimo\n",
        "optimal_threshold = 0.08675912022590637\n",
        "y_pred_optimal = [1 if prob > optimal_threshold else 0 for prob in y_probs]\n",
        "\n",
        "# Generar matrices de confusión\n",
        "cm_default = confusion_matrix(y_true, y_pred_default)\n",
        "cm_optimal = confusion_matrix(y_true, y_pred_optimal)\n",
        "\n",
        "# Función para visualizar la matriz de confusión\n",
        "def plot_confusion_matrix(cm, title, labels=['Clase 0', 'Clase 1']):\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Predicción')\n",
        "    plt.ylabel('Verdadero')\n",
        "    plt.show()\n",
        "\n",
        "# Visualizar matriz con umbral por defecto\n",
        "plot_confusion_matrix(cm_default, 'Matriz de Confusión - Umbral por Defecto (0.5)')\n",
        "\n",
        "# Visualizar matriz con umbral óptimo\n",
        "plot_confusion_matrix(cm_optimal, f'Matriz de Confusión - Umbral Óptimo ({optimal_threshold:.4f})')\n",
        "\n",
        "# Generar reporte de clasificación con ambos umbrales\n",
        "print(\"Reporte de Clasificación - Umbral por Defecto (0.5):\")\n",
        "print(classification_report(y_true, y_pred_default))\n",
        "\n",
        "print(\"\\nReporte de Clasificación - Umbral Óptimo:\")\n",
        "print(classification_report(y_true, y_pred_optimal))\n"
      ],
      "metadata": {
        "id": "2ePuDk6Kj6FR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegúrate de que y_pred_optimal esté calculado y agregado al DataFrame\n",
        "df_test['y_pred_optimal'] = [1 if prob > optimal_threshold else 0 for prob in y_probs]\n",
        "\n",
        "# Identificar los falsos positivos y falsos negativos\n",
        "falsos_positivos = df_test[(df_test['label'] == 0) & (df_test['y_pred_optimal'] == 1)]\n",
        "falsos_negativos = df_test[(df_test['label'] == 1) & (df_test['y_pred_optimal'] == 0)]\n",
        "\n",
        "# Mostrar ejemplos\n",
        "print(\"Falsos Positivos (Clase 0 predicha como 1):\")\n",
        "print(falsos_positivos['content'].head())\n",
        "\n",
        "print(\"\\nFalsos Negativos (Clase 1 predicha como 0):\")\n",
        "print(falsos_negativos['content'].head())\n"
      ],
      "metadata": {
        "id": "xvgHKxTv9IIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar promotores y detractores\n",
        "promotores = sum(1 for pred in y_pred if pred == 1)  # Comentarios positivos (Promotores)\n",
        "detractores = sum(1 for pred in y_pred if pred == 0)  # Comentarios negativos (Detractores)\n",
        "\n",
        "# Calcular el total de comentarios\n",
        "total_comentarios = len(y_pred)\n",
        "\n",
        "# Calcular el NPS\n",
        "nps = ((promotores - detractores) / total_comentarios) * 100\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f\"Promotores (Positivos): {promotores}\")\n",
        "print(f\"Detractores (Negativos): {detractores}\")\n",
        "print(f\"Total de Comentarios: {total_comentarios}\")\n",
        "print(f\"NPS: {nps:.2f}\")\n"
      ],
      "metadata": {
        "id": "eVpprCKP_5G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Aplicamos el modelo a todo el dataset con el fin de identificar el total de comentarios positivos y negativos, así calcularemos el NPS homologando Detractor = Comentario Negativo, Promotor = Comentario Positivo.\n",
        "Luego se hará una comparación vs el NPS calculado desde el lado de las calificaciones o número de estrellas\n",
        "'''"
      ],
      "metadata": {
        "id": "rmlT_dauBwV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataLoader para todos los comentarios\n",
        "class AllCommentsDataset(Dataset):\n",
        "    def __init__(self, contents, tokenizer, max_len):\n",
        "        self.contents = contents\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.contents)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        content = str(self.contents[idx])\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            content,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten()\n",
        "        }\n",
        "\n",
        "# Preparar el DataLoader para todos los comentarios\n",
        "all_comments_dataset = AllCommentsDataset(\n",
        "    contents=df['content'].to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=CONFIG['max_len']\n",
        ")\n",
        "all_comments_loader = DataLoader(all_comments_dataset, batch_size=CONFIG['batch_size'], num_workers=2)\n",
        "\n",
        "# Hacer predicciones para todos los comentarios\n",
        "all_preds = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in all_comments_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "# Agregar las predicciones al DataFrame original\n",
        "df['predicted_label'] = all_preds\n",
        "\n",
        "# Calcular el NPS\n",
        "promotores = df[df['predicted_label'] == 1].shape[0]  # Comentarios positivos\n",
        "detractores = df[df['predicted_label'] == 0].shape[0]  # Comentarios negativos\n",
        "total_comentarios = len(df)\n",
        "\n",
        "nps_total = ((promotores - detractores) / total_comentarios) * 100\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f\"Total de comentarios: {total_comentarios}\")\n",
        "print(f\"Promotores (Positivos): {promotores}\")\n",
        "print(f\"Detractores (Negativos): {detractores}\")\n",
        "print(f\"NPS Total: {nps_total:.2f}\")\n"
      ],
      "metadata": {
        "id": "crbkfJD4AY79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Calcular el NPS real basado en las calificaciones originales\n",
        "df['real_label'] = df['score'].apply(lambda x: 0 if x <= 3 else (1 if x == 5 else None))  # Neutros excluidos\n",
        "\n",
        "# Contar detractores y promotores reales\n",
        "detractores_reales = df[df['real_label'] == 0].shape[0]\n",
        "promotores_reales = df[df['real_label'] == 1].shape[0]\n",
        "total_comentarios_reales = detractores_reales + promotores_reales  # Excluimos neutros\n",
        "\n",
        "# Calcular NPS real\n",
        "nps_real = ((promotores_reales - detractores_reales) / total_comentarios_reales) * 100\n",
        "\n",
        "# 2. Calcular el NPS predicho basado en el modelo\n",
        "promotores_predichos = df[df['predicted_label'] == 1].shape[0]\n",
        "detractores_predichos = df[df['predicted_label'] == 0].shape[0]\n",
        "total_comentarios_predichos = len(df)\n",
        "\n",
        "# Calcular NPS predicho\n",
        "nps_predicho = ((promotores_predichos - detractores_predichos) / total_comentarios_predichos) * 100\n",
        "\n",
        "# 3. Comparar ambos NPS\n",
        "print(f\"Resultados de NPS:\")\n",
        "print(f\"NPS Real (Basado en calificaciones originales): {nps_real:.2f}\")\n",
        "print(f\"NPS Predicho (Basado en modelo): {nps_predicho:.2f}\")\n",
        "\n",
        "# Opcional: Comparar distribución de comentarios reales y predichos\n",
        "print(\"\\nDistribución de comentarios:\")\n",
        "print(f\"Detractores reales: {detractores_reales}, Promotores reales: {promotores_reales}\")\n",
        "print(f\"Detractores predichos: {detractores_predichos}, Promotores predichos: {promotores_predichos}\")\n"
      ],
      "metadata": {
        "id": "oe6prlCxA5TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar comentarios negativos\n",
        "comentarios_negativos = df[df['predicted_label'] == 0]['content']\n",
        "print(f\"Total de comentarios negativos: {len(comentarios_negativos)}\")\n"
      ],
      "metadata": {
        "id": "FjtrAOh-Bh4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn sentence-transformers spacy pandas\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "id": "wiG_XtTbRdoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Cargar modelo de idioma en español\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "# Modelo para embeddings de oraciones\n",
        "embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "# Función para extraer frases completas con contexto\n",
        "def extraer_frases_completas(texto):\n",
        "    \"\"\"\n",
        "    Extrae frases contextualmente completas del texto.\n",
        "    \"\"\"\n",
        "    doc = nlp(texto)\n",
        "    frases = []\n",
        "    for sent in doc.sents:  # Iterar sobre oraciones completas\n",
        "        sustantivos = [token for token in sent if token.pos_ == \"NOUN\"]\n",
        "        if sustantivos:\n",
        "            # Construir frases con sustantivos y modificadores relevantes\n",
        "            for noun in sustantivos:\n",
        "                modificadores = [child.text for child in noun.children if child.pos_ in {\"ADJ\", \"VERB\", \"ADV\"}]\n",
        "                frase = f\"{noun.text} {' '.join(modificadores)}\"\n",
        "                frases.append(frase.strip())\n",
        "    return frases\n",
        "\n",
        "# Extraer comentarios negativos del DataFrame\n",
        "comentarios_negativos = df[df['predicted_label'] == 0]['content'].dropna().tolist()\n",
        "\n",
        "# Preprocesar los comentarios negativos para extraer frases completas\n",
        "comentarios_frases = []\n",
        "for comentario in comentarios_negativos:\n",
        "    frases = extraer_frases_completas(comentario)\n",
        "    comentarios_frases.extend(frases)\n",
        "\n",
        "# Validar que no estén vacías\n",
        "if not comentarios_frases:\n",
        "    raise ValueError(\"No hay frases clave válidas después del procesamiento.\")\n",
        "\n",
        "# Obtener embeddings semánticos para frases completas\n",
        "embeddings = embedder.encode(comentarios_frases)\n",
        "\n",
        "# Agrupar frases similares usando K-Means\n",
        "num_clusters = 5  # Número de temas que queremos encontrar\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
        "kmeans.fit(embeddings)\n",
        "\n",
        "# Asociar frases a sus respectivos clusters\n",
        "comentarios_cluster = pd.DataFrame({\n",
        "    'frase': comentarios_frases,\n",
        "    'cluster': kmeans.labels_\n",
        "})\n",
        "\n",
        "# Función para seleccionar frases representativas completas\n",
        "def obtener_frases_representativas_completas(cluster_df, num_frases=5):\n",
        "    \"\"\"\n",
        "    Selecciona frases completas más representativas para cada cluster.\n",
        "    \"\"\"\n",
        "    frases_por_cluster = {}\n",
        "    for cluster in sorted(cluster_df['cluster'].unique()):\n",
        "        frases = cluster_df[cluster_df['cluster'] == cluster]['frase'].tolist()\n",
        "        if not frases:\n",
        "            continue  # Saltar clusters vacíos\n",
        "        # Seleccionar las frases más frecuentes\n",
        "        frases_frecuentes = [frase for frase, _ in Counter(frases).most_common(num_frases)]\n",
        "        frases_por_cluster[f\"Tema {cluster + 1}\"] = frases_frecuentes\n",
        "    return frases_por_cluster\n",
        "\n",
        "# Obtener frases representativas para cada cluster\n",
        "temas = obtener_frases_representativas_completas(comentarios_cluster)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"\\nTemas principales de comentarios negativos (con frases completas):\")\n",
        "for tema, frases in temas.items():\n",
        "    print(f\"{tema}: {', '.join(frases)}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "moKt6d0nCM0q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}